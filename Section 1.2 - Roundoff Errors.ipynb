{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2: Round-off Errors and Computer Arithmetic\n",
    "\n",
    "## Floating-point arithmetic\n",
    "\n",
    "Real numbers are stored on a computer following the IEEE floating-point standard:\n",
    "\n",
    "1. **half precision** using 16 bits (Julia type: `Float16`)\n",
    "2. **single precision** using 32 bits (Julia type: `Float32`)\n",
    "3. **double precision** using 64 bits (Julia type: `Float64`)\n",
    "\n",
    "Julia also has an **arbitrary precision** floating-point data type called `BigFloat`. It is excellent if you need more **precision**, but it is also much **slower**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of IEEE double floating-point format (`Float64`)\n",
    "\n",
    "Suppose $x$ is a floating-point number stored in the following 64-bits:\n",
    "\n",
    "| 1 | 2 | $\\cdots$ | 12 | 13 | $\\cdots$ | 64 |\n",
    "|:-:|:-:|:--------:|:--:|:--:|:--------:|:--:|\n",
    "|$s$|$e_{10}$| $\\cdots$ |$e_0$|$f_1$|$\\cdots$|$f_{52}$|\n",
    "\n",
    "- 1 bit $s$ represents the **sign**\n",
    "- 11 bits $e_{10} \\cdots e_{0}$ represent the **exponent**\n",
    "- 52 bits $f_1 \\cdots f_{52}$ represent the **fraction** (a.k.a. the mantissa or significand)\n",
    "\n",
    "Then\n",
    "\n",
    "$$ x = (-1)^s \\left[1.f_1 \\cdots f_{52}\\right]_2 \\times 2^{(e-1023)}.$$\n",
    "\n",
    "Notes: \n",
    "\n",
    "- $x$ is **normalized** to have its first digit nonzero.\n",
    "- $$e = \\left[e_{10} \\cdots e_{0}\\right]_2 = e_{10} 2^{10} + \\cdots + e_1 2^1 + e_0 2^0 \\in \\left[0, 2^{11}-1\\right] = [0, 2047]$$\n",
    "- $e = 0$ and $e = 2047$ are reserved for special floating-point values, so \n",
    "\n",
    "$$e \\in [1, 2046]$$\n",
    "\n",
    "- the \"$-1023$\" in the exponent is called the **bias**:  $e-1023 \\in [-1022,1023]$ (**In the book is considered the bias exponent in $[-1023,1024]$**)\n",
    "- $$\\left[1.f_1 \\cdots f_{52}\\right]_2 = 1 + \\frac{f_1}{2^1} + \\frac{f_2}{2^2} + \\cdots + \\frac{f_{52}}{2^{52}}$$\n",
    "in base $2$.\n",
    "\n",
    "![title](Mantissa2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "x & = -[1.101101]_2 \\times 2^{(1026-1023)} \\\\\n",
    "  & = -[1.101101]_2 \\times 2^{3} \\\\\n",
    "  & = -[1101.101]_2 \\\\\n",
    "  & = -\\left(1 \\cdot 8 + 1 \\cdot 4 + 0 \\cdot 2 + 1 \\cdot 2^0 + 1 \\cdot \\frac{1}{2} + 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{8}\\right)  \\\\\n",
    "  & = -13.625\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mb\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m\u001b[1ms\u001b[22m is\u001b[1mb\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m\u001b[1ms\u001b[22m flip\u001b[1mb\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22m\u001b[1ms\u001b[22m! \u001b[1mb\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22mbroadca\u001b[1ms\u001b[22mt \u001b[1mb\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22mrand \u001b[1mB\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22mArray \u001b[1mB\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22mVector \u001b[1mB\u001b[22m\u001b[1mi\u001b[22m\u001b[1mt\u001b[22mMatrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "bits(n)\n",
       "```\n",
       "\n",
       "A string giving the literal bit representation of a number.\n",
       "\n",
       "```jldoctest\n",
       "julia> bits(4)\n",
       "\"0000000000000000000000000000000000000000000000000000000000000100\"\n",
       "\n",
       "julia> bits(2.2)\n",
       "\"0100000000000001100110011001100110011001100110011001100110011010\"\n",
       "```\n"
      ],
      "text/plain": [
       "```\n",
       "bits(n)\n",
       "```\n",
       "\n",
       "A string giving the literal bit representation of a number.\n",
       "\n",
       "```jldoctest\n",
       "julia> bits(4)\n",
       "\"0000000000000000000000000000000000000000000000000000000000000100\"\n",
       "\n",
       "julia> bits(2.2)\n",
       "\"0100000000000001100110011001100110011001100110011001100110011010\"\n",
       "```\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', \"10000000010\", \"1011010000000000000000000000000000000000000000000000\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bits(-13.625)\n",
    "s[1], s[2:12], s[13:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Even if a number can be represented exactly in base-10 with a finite number of digits, it may require an infinite number of digits in base-2.\n",
    "\n",
    "$$\n",
    "0.1 = \\left[0.000110011001\\ldots\\right]_2 = \\left[1.\\overline{1001}\\right]_2 \\times 2^{-4}\n",
    "$$\n",
    "\n",
    "Therefore, $0.1$ cannot be represented exactly as a floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0',\"01111111011\",\"1001100110011001100110011001100110011001100110011010\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bits(0.1)\n",
    "s[1], s[2:12], s[13:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of floating-point numbers\n",
    "\n",
    "- **Largest** `Float64` $= \\left(2 - 2^{-52}\\right) \\times 2^{1023} \\approx 2 \\times 10^{308}$\n",
    "- **Smallest positive normalized** `Float64` $= 2^{-1022} \\approx 2 \\times 10^{-308}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22m\u001b[1ml\u001b[22m\u001b[1mm\u001b[22m\u001b[1ma\u001b[22m\u001b[1mx\u001b[22m \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22m\u001b[1ml\u001b[22m\u001b[1mm\u001b[22min \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22mdd\u001b[1ml\u001b[22m\u001b[1mm\u001b[22m \u001b[1mR\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22mdOn\u001b[1ml\u001b[22my\u001b[1mM\u001b[22memoryError\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "realmax(T)\n",
       "```\n",
       "\n",
       "The highest finite value representable by the given floating-point DataType `T`.\n",
       "\n",
       "```jldoctest\n",
       "julia> realmax(Float16)\n",
       "Float16(6.55e4)\n",
       "\n",
       "julia> realmax(Float32)\n",
       "3.4028235f38\n",
       "```\n"
      ],
      "text/plain": [
       "```\n",
       "realmax(T)\n",
       "```\n",
       "\n",
       "The highest finite value representable by the given floating-point DataType `T`.\n",
       "\n",
       "```jldoctest\n",
       "julia> realmax(Float16)\n",
       "Float16(6.55e4)\n",
       "\n",
       "julia> realmax(Float32)\n",
       "3.4028235f38\n",
       "```\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?realmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7976931348623157e308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with realmax\n",
    "x = realmax(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0',\"11111111110\",\"1111111111111111111111111111111111111111111111111111\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bits(x)\n",
    "s[1], s[2:12], s[13:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x + 1) - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22m\u001b[1ml\u001b[22m\u001b[1mm\u001b[22m\u001b[1mi\u001b[22m\u001b[1mn\u001b[22m \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22m\u001b[1ml\u001b[22m\u001b[1mm\u001b[22max \u001b[1mr\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22mdd\u001b[1ml\u001b[22m\u001b[1mm\u001b[22m \u001b[1mR\u001b[22m\u001b[1me\u001b[22m\u001b[1ma\u001b[22mdOn\u001b[1ml\u001b[22my\u001b[1mM\u001b[22memoryError\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "realmin(T)\n",
       "```\n",
       "\n",
       "The smallest in absolute value non-subnormal value representable by the given floating-point DataType `T`.\n"
      ],
      "text/plain": [
       "```\n",
       "realmin(T)\n",
       "```\n",
       "\n",
       "The smallest in absolute value non-subnormal value representable by the given floating-point DataType `T`.\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?realmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with realmin\n",
    "x = realmin(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', \"00000000001\", \"0000000000000000000000000000000000000000000000000000\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bits(x)\n",
    "s[1], s[2:12], s[13:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x + 1.0) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other special floats\n",
    "\n",
    "- `0.0` and `-0.0`: $$e_{10} \\cdots e_0 = 0 \\cdots 0 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `Inf` and `-Inf`: $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `NaN` (not-a-number): $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} \\neq 0$$\n",
    "\n",
    "From [Julia Manual: Mathematical Operations and Elementary Functions](http://julia.readthedocs.org/en/latest/manual/mathematical-operations/):\n",
    "\n",
    "- `Inf` is equal to itself and greater than everything else except `NaN`.\n",
    "- `-Inf` is equal to itself and less then everything else except `NaN`.\n",
    "- `NaN` is not equal to, not less than, and not greater than anything, including itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with 0.0, -0.0, Inf, -Inf, and NaN\n",
    "\n",
    "1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).",
      "",
      "Stacktrace:",
      " [1] \u001b[1msqrt\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Float64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./math.jl:425\u001b[22m\u001b[22m",
      " [2] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "sqrt(-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0 + 1.0im"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(-1.0 + 0.0im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0 < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(-0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0 == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0 === 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaN == NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaN === NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0111111111111000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Inf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Inf"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0/-0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inf/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inf/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaN + 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine epsilon `eps(Float64)` and the unit roundoff $\\eta$\n",
    "\n",
    "- `1.0 + eps(Float64)` is the **first** `Float64` that is **larger** than `1.0`\n",
    "\n",
    "$$\\mathtt{eps(Float64)} = 2^{-52} \\approx 2.2 \\times 10^{-16}$$\n",
    "\n",
    "- $\\eta = $ `eps(Float64)/2.0` is the largest possible **relative error** due to roundoff\n",
    "\n",
    "$$\\eta = 2^{-53} \\approx 1.1 \\times 10^{-16}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1me\u001b[22m\u001b[1mp\u001b[22m\u001b[1ms\u001b[22m R\u001b[1me\u001b[22m\u001b[1mp\u001b[22m\u001b[1mS\u001b[22mtring @\u001b[1me\u001b[22mla\u001b[1mp\u001b[22m\u001b[1ms\u001b[22med ind\u001b[1me\u001b[22mx\u001b[1mp\u001b[22mid\u001b[1ms\u001b[22m \u001b[1me\u001b[22mx\u001b[1mp\u001b[22mandu\u001b[1ms\u001b[22mer \u001b[1me\u001b[22msca\u001b[1mp\u001b[22me_\u001b[1ms\u001b[22mtring s\u001b[1me\u001b[22mt\u001b[1mp\u001b[22mreci\u001b[1ms\u001b[22mion\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "eps(T)\n",
       "```\n",
       "\n",
       "The distance between 1.0 and the next larger representable floating-point value of `DataType` `T`. Only floating-point types are sensible arguments.\n",
       "\n",
       "```\n",
       "eps()\n",
       "```\n",
       "\n",
       "The distance between 1.0 and the next larger representable floating-point value of `Float64`.\n",
       "\n",
       "```\n",
       "eps(x)\n",
       "```\n",
       "\n",
       "The distance between `x` and the next larger representable floating-point value of the same `DataType` as `x`.\n",
       "\n",
       "```\n",
       "eps(::DateTime) -> Millisecond\n",
       "eps(::Date) -> Day\n",
       "```\n",
       "\n",
       "Returns `Millisecond(1)` for `DateTime` values and `Day(1)` for `Date` values.\n"
      ],
      "text/plain": [
       "```\n",
       "eps(T)\n",
       "```\n",
       "\n",
       "The distance between 1.0 and the next larger representable floating-point value of `DataType` `T`. Only floating-point types are sensible arguments.\n",
       "\n",
       "```\n",
       "eps()\n",
       "```\n",
       "\n",
       "The distance between 1.0 and the next larger representable floating-point value of `Float64`.\n",
       "\n",
       "```\n",
       "eps(x)\n",
       "```\n",
       "\n",
       "The distance between `x` and the next larger representable floating-point value of the same `DataType` as `x`.\n",
       "\n",
       "```\n",
       "eps(::DateTime) -> Millisecond\n",
       "eps(::Date) -> Day\n",
       "```\n",
       "\n",
       "Returns `Millisecond(1)` for `DateTime` values and `Day(1)` for `Date` values.\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with eps\n",
    "ϵ = eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 + ϵ == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 + ϵ/2.0 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextfloat(1.0) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error example\n",
    "\n",
    "Suppose we are using a base-10 floating-point system with 4 significant digits, using `RoundNearest`:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\left( 1.112 \\times 10^1 \\right) \\times \\left( 1.112 \\times 10^2 \\right)\n",
    "& = 1.236544 \\times 10^3 \\\\\n",
    "& \\rightarrow 1.237 \\times 10^3 = 1237\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "The **absolute error** is $1237 - 1236.544 = 0.456$.\n",
    "\n",
    "The **relative error** is $$\\frac{0.456}{1236.544} \\approx 0.0004 = 0.04 \\%$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x32efa3590>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Study the effect of roundoff error by plotting \n",
    "# the absolute error and relative error of converting \n",
    "# Float64 numbers to Float32\n",
    "\n",
    "η = eps(Float32)/2.0\n",
    "\n",
    "x = Array(linspace(-10.0, 10.0, 10000))\n",
    "y = map(Float32, x)     # Convert x to Float32\n",
    "abserr = abs(x - y)     # Absolute roundoff errors\n",
    "relerr = abserr./abs(x) # Relative roundoff errors\n",
    "\n",
    "using PyPlot\n",
    "\n",
    "subplot(1, 2, 1)\n",
    "plot(x, abserr)\n",
    "ylim(0.0, maximum(abserr))\n",
    "title(\"Absolute error\")\n",
    "\n",
    "subplot(1, 2, 2)\n",
    "plot(x, relerr)\n",
    "plot(x, η*ones(x), \"r\")\n",
    "ylim(0.0, maximum(abserr))\n",
    "title(\"Relative error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default rounding mode is `RoundNearest` (round to the nearest floating-point number). This implies that\n",
    "\n",
    "$$ \\frac{|x - \\mathrm{fl}(x)|}{|x|} \\leq \\eta.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error accumulation\n",
    "\n",
    "When performing arithmetic operations on floats, extra **guard digits** are used to ensure **exact rounding**. This guarantees that the relative error of a floating-point operation (**flop**) is small. More precisely, for floating-point numbers $x$ and $y$, we have\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mathrm{fl}(x \\pm y) &= (x \\pm y)(1 + \\varepsilon_1) \\\\\n",
    "\\mathrm{fl}(x \\times y) &= (x \\times y)(1 + \\varepsilon_2) \\\\\n",
    "\\mathrm{fl}(x \\div y) &= (x \\div y)(1 + \\varepsilon_3) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where $|\\varepsilon_i| \\leq \\eta$, for $i = 1,2,3$, where $\\eta$ is the unit roundoff.\n",
    "\n",
    "Although the relative error of each flop is small, it is possible to have the roundoff error accumulate and create significant error in the final result. If $E_n$ is the error after $n$ flops, then:\n",
    "\n",
    "- **linear roundoff error accumulation** is when $E_n \\approx c_0 n E_0$\n",
    "- **exponential roundoff error accumulation** is when $E_n \\approx c_1^n E_0$, for some $c_1 > 1$\n",
    "\n",
    "In general, linear roundoff error accumulation is unavoidable. On the other hand, exponential roundoff error accumulation is not acceptable and is an indication of an **unstable algorithm**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General advice\n",
    "\n",
    "1. Adding $x + y$ when $|x| \\gg |y|$ can cause the information in $y$ to be 'lost' in the summation.\n",
    "\n",
    "2. Dividing by very small numbers or multiplying by very large numbers can **magnify error**.\n",
    "\n",
    "3. Subtracting numbers that are almost equal produces **cancellation error**.\n",
    "\n",
    "4. An **overflow** occurs when the result is too large in magnitude to be representable as a float. Result will become either `Inf` or `-Inf`. Overflows should be avoided.\n",
    "\n",
    "4. An **underflow** occurs when the result is too small in magnitude to be representable as a float. Result will become either `0.0` or `-0.0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (summation order)\n",
    "\n",
    "This next example shows that summation order can make a difference. We will compute\n",
    "\n",
    "$$\n",
    "s = \\sum_{n = 1}^{1,000,000} \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "in three different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.997896413852555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum from largest to smallest\n",
    "s1 = 0.0\n",
    "for n = 1:1e8\n",
    "    s1 += 1.0/n\n",
    "end\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.997896413853447"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum from smallest to largest\n",
    "s2 = 0.0\n",
    "for n = 1e8:-1:1\n",
    "    s2 += 1.0/n\n",
    "end\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.99789641384885"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum largest to smallest and so on\n",
    "s3 = 0.0\n",
    "for n = 1:(1e8)/2\n",
    "    s3 += 1.0/n + 1/(1e8-n+1)\n",
    "end\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.693841433563712e-14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(s1 - s2)/s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9504687709987854e-13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(s1 - s3)/s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (cancellation error)\n",
    "\n",
    "Show that \n",
    "\n",
    "$$\n",
    "\\ln\\left( x - \\sqrt{x^2-1} \\right) = -\\ln\\left( x + \\sqrt{x^2-1} \\right).\n",
    "$$\n",
    "\n",
    "Which formula is more suitable for numerical computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.714973875118524\n",
      "-18.420680743952367\n"
     ]
    }
   ],
   "source": [
    "# Experiment with both formulas\n",
    "x = 1e8/2\n",
    "f1 = log(x - sqrt(x^2 - 1))\n",
    "f2 = -log(x + sqrt(x^2 - 1))\n",
    "\n",
    "println(f1)\n",
    "println(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015725008922262945"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(f1 - f2)/abs(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (four-digit rounding arithmetic)\n",
    "The quadratic formula to find the roots of \n",
    "### $$x^2+bx+c=0\\qquad \\mbox{are}\\qquad x_1=\\frac{-b+\\sqrt{b^2-4c}}{2} \\quad \\mbox{and} \\quad x_2=\\frac{-b-\\sqrt{b^2-4c}}{2}.$$\n",
    "Using four-digit rounding arithmetic; consider this formula applied to the equation \n",
    "### $$x^2+62.10x+1=0$$ \n",
    "whose roots are\n",
    "### $$x_1=-0.01610723 \\quad \\mbox{and} \\quad x_2=-62.08390.$$ \n",
    "Here, $b$ and $\\sqrt{b^2-4c}$ are nearly equal numbers, since $b^2$ is much larger than $4a$. So,\n",
    "### $$\\sqrt{b^2-4c}=\\sqrt{(62.10)^2-(4.000)(1.000)}=\\sqrt{3856-4.000}=\\sqrt{3852}=62.06$$\n",
    "and \n",
    "### $$\\mathrm{fl}(x_1)=\\frac{-62.10+62.06}{2}=-0.02000,$$\n",
    "a poor approximation of $x_1=-0.01610723$ with **relative error** \n",
    "### $$2.4\\times 10^{-1}.$$\n",
    "To obtain a more accurate four-digit rounding approximation for $x_1$, we change the quadratic formula by rationalizing the numerator:\n",
    "### $$x_1=\\frac{-b+\\sqrt{b^2-4c}}{2}\\left(\\frac{-b-\\sqrt{b^2-4c}}{-b-\\sqrt{b^2-4c}}\\right)=\\frac{-2c}{b+\\sqrt{b^2-4c}}.$$\n",
    "In this case: \n",
    "### $$\\mathrm{fl}(x_1)=\\frac{-2.000}{62.10+62.06}=\\frac{-2.000}{124.2}=-0.01610,$$ \n",
    "which has the small **relative error** \n",
    "### $$6.2\\times 10^{-4}.$$\n",
    "However, this rationalization technique can lead the large **relative error**  \n",
    "### $$1.9\\times 10^{-1}.$$ \n",
    "for $\\mathrm{fl}(x_2)$. Note that the formula \n",
    "### $$x_2=\\frac{-2c}{b-\\sqrt{b^2-4c}} \\qquad \\mbox{and} \\qquad \\mathrm{fl}(x_2)=-50.00.$$\n",
    "The **absolute error** is $12$!!! \n",
    "\n",
    "## $$\n",
    "\\mbox{The lesson: Think before you compute!}\n",
    "$$\n",
    "\n",
    "Accuracy loss due to round-off error can also be reduced by reduce calculations.\n",
    "\n",
    "## Example (evaluate a polynomial): \n",
    "Evaluate $f(x)= x^3 − 6.1x^2 + 3.2x + 1.5$ at $x = 4.71$ using three-digit arithmetic.\n",
    "\n",
    "**Exact:** $$f (4.71) = 104.487111 − 135.32301 + 15.072 + 1.5 = −14.263899.$$\n",
    "\n",
    "**Three-digit (rounding)**: $$f (4.71) = ((105. - 135.) + 15.1) + 1.5 = −13.4.$$\n",
    "\n",
    "An alternative approach is: (**Nested or Ruffini Algorithm**)\n",
    "\n",
    "$$f(x)=x^3 −6.1x^2 +3.2x+1.5=((x−6.1)x+3.2)x+1.5.$$\n",
    "Using **three-digit rounding** arithmetic now produces\n",
    "\n",
    "$$\\begin{align}f (4.71) &= ((4.71 - 6.1)4.71 + 3.2)4.71 + 1.5 \\\\&= ((−1.39)(4.71) + 3.2)4.71 + 1.5 \\\\&= (-6.55 + 3.2)4.71 + 1.5 \\\\&= (-3.35)4.71 + 1.5 \\\\&= −15.8 + 1.5\\\\ &= -14.3.\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
